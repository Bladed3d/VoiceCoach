<!DOCTYPE html>
<html>
<head>
    <title>Microphone Test</title>
    <style>
        body { 
            font-family: Arial; 
            padding: 20px; 
            background: #1a1a1a; 
            color: white;
        }
        #level {
            width: 100%;
            height: 40px;
            background: #333;
            border-radius: 5px;
            overflow: hidden;
            margin: 20px 0;
        }
        #levelBar {
            height: 100%;
            background: #4CAF50;
            width: 0%;
            transition: width 0.1s;
        }
        button {
            padding: 10px 20px;
            font-size: 16px;
            margin: 10px;
            cursor: pointer;
        }
        #log {
            background: #222;
            padding: 10px;
            border-radius: 5px;
            max-height: 300px;
            overflow-y: auto;
            font-family: monospace;
            font-size: 12px;
        }
    </style>
</head>
<body>
    <h1>ðŸŽ¤ Simple Microphone Test</h1>
    
    <button id="startBtn">Start Microphone</button>
    <button id="stopBtn" disabled>Stop</button>
    
    <div id="level">
        <div id="levelBar"></div>
    </div>
    
    <div>Audio Level: <span id="levelText">0%</span></div>
    
    <h3>Debug Log:</h3>
    <div id="log"></div>

    <script>
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const levelBar = document.getElementById('levelBar');
        const levelText = document.getElementById('levelText');
        const log = document.getElementById('log');
        
        let audioContext;
        let analyser;
        let microphone;
        let stream;
        let animationId;
        
        function addLog(message) {
            const time = new Date().toLocaleTimeString();
            log.innerHTML += `[${time}] ${message}<br>`;
            log.scrollTop = log.scrollHeight;
        }
        
        startBtn.addEventListener('click', async () => {
            try {
                addLog('Requesting microphone access...');
                
                // Get microphone
                stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false
                    } 
                });
                
                addLog('âœ… Microphone access granted');
                
                // Create audio context
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                addLog(`Audio context created: ${audioContext.state}, Sample rate: ${audioContext.sampleRate}Hz`);
                
                // Create analyser
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                analyser.smoothingTimeConstant = 0.3;
                
                // Connect microphone to analyser
                microphone = audioContext.createMediaStreamSource(stream);
                microphone.connect(analyser);
                addLog('Microphone connected to analyser');
                
                // Start monitoring
                startBtn.disabled = true;
                stopBtn.disabled = false;
                monitorAudio();
                
            } catch (error) {
                addLog(`âŒ Error: ${error.message}`);
                console.error(error);
            }
        });
        
        stopBtn.addEventListener('click', () => {
            if (animationId) {
                cancelAnimationFrame(animationId);
            }
            if (audioContext) {
                audioContext.close();
            }
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
            
            levelBar.style.width = '0%';
            levelText.textContent = '0%';
            startBtn.disabled = false;
            stopBtn.disabled = true;
            addLog('Stopped');
        });
        
        function monitorAudio() {
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            
            function update() {
                analyser.getByteTimeDomainData(dataArray);
                
                // Calculate volume from time domain data
                let sum = 0;
                for (let i = 0; i < dataArray.length; i++) {
                    const sample = Math.abs(dataArray[i] - 128);
                    sum += sample;
                }
                
                const average = sum / dataArray.length;
                const level = Math.min(100, (average / 64) * 100);
                
                levelBar.style.width = level + '%';
                levelText.textContent = level.toFixed(1) + '%';
                
                // Color based on level
                if (level > 70) {
                    levelBar.style.background = '#f44336';
                } else if (level > 40) {
                    levelBar.style.background = '#FF9800';
                } else {
                    levelBar.style.background = '#4CAF50';
                }
                
                animationId = requestAnimationFrame(update);
            }
            
            update();
        }
    </script>
</body>
</html>